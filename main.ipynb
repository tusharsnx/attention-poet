{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit (windows store)"
  },
  "interpreter": {
   "hash": "45d71518a53edb0c7945009ff994c882d98481b890dfc9d0db3c03b626f79264"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import tensorflow as tf\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import seaborn as sns\r\n",
    "import pickle as pkl\r\n",
    "\r\n",
    "from model.preprocess import Preprocessor\r\n",
    "from model.callbacks import SeqGenerateCallback\r\n",
    "from model.model import Poet\r\n",
    "from model.metrics import MaskedAccuracy, MaskedLoss"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "MAX_VOCAB_SIZE = 10000\r\n",
    "EMBEDDING_DIM = 200\r\n",
    "DFF = 512\r\n",
    "D_MODEL = 256\r\n",
    "MAX_SEQ_LEN = 10\r\n",
    "TEMP_DATA = False"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "if not TEMP_DATA:\r\n",
    "    data = pd.read_csv(\"datasets/data.tsv\", sep=\"\\t\")\r\n",
    "else:\r\n",
    "    data = pd.read_csv(\"datasets/preprocessed_data.tsv\", sep=\"\\t\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "data.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                        lines\n",
       "0     सदियों से बदनाम हुआ हूं\n",
       "1       किसी एक के नही सभी के\n",
       "2     हाथों से मै छला गया हूं\n",
       "3  भला , बुरा , बीता और गुजरा\n",
       "4        दगाबाज धोखा देता हूं"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>सदियों से बदनाम हुआ हूं</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>किसी एक के नही सभी के</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>हाथों से मै छला गया हूं</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>भला , बुरा , बीता और गुजरा</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>दगाबाज धोखा देता हूं</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "total_dataset_len = len(data.iloc[:, :])\r\n",
    "test_split = 0.1\r\n",
    "train_index_limit = int((1-test_split)*total_dataset_len)\r\n",
    "train_data = data.iloc[:train_index_limit, :1]\r\n",
    "val_data = data.iloc[train_index_limit:, :1]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "train_data.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(8379, 1)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "preprocessor = Preprocessor(max_vocab_size=10000, seq_len=14)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "vocab = preprocessor.build_vocab(train_data.values)\r\n",
    "x_train_seq, y_train_seq = preprocessor(train_data, training=True)\r\n",
    "x_val_seq, y_val_seq = preprocessor(val_data, training=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "preprocessor.tokenizer.get_config()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'name': 'text_vectorization',\n",
       " 'trainable': True,\n",
       " 'dtype': 'string',\n",
       " 'max_tokens': 10000,\n",
       " 'standardize': <bound method Preprocessor._custom_standardize of <model.preprocess.Preprocessor object at 0x000001DA57ECDEB0>>,\n",
       " 'split': 'whitespace',\n",
       " 'ngrams': None,\n",
       " 'output_mode': 'int',\n",
       " 'output_sequence_length': 14,\n",
       " 'pad_to_max_tokens': False,\n",
       " 'vocabulary_size': 8934}"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "x_train_seq.shape, y_train_seq.shape, x_val_seq.shape, y_val_seq.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(TensorShape([8379, 14]),\n",
       " TensorShape([8379, 14]),\n",
       " TensorShape([932, 14]),\n",
       " TensorShape([932, 14]))"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "x_train_seq[:1]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 14), dtype=int64, numpy=\n",
       "array([[   2,  458,    8, 1333,   84,   54,    3,    0,    0,    0,    0,\n",
       "           0,    0,    0]], dtype=int64)>"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "print(\"few vocab tokens:\", vocab[:10])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "few vocab tokens: ['', '[UNK]', '[SURU]', '[KHATAM]', ',', 'है', '।', 'में', 'से', 'की']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "print(\"Vocab Size: \", preprocessor.vocab_size)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Vocab Size:  8934\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "with open(\"embedding-100.pkl\", \"rb\") as f:\r\n",
    "    embeddings = pkl.load(f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "model = Poet(\r\n",
    "    preprocessor=preprocessor, \r\n",
    "    num_blocks=4, \r\n",
    "    d_model=256, \r\n",
    "    dff=512, \r\n",
    "    heads=8, \r\n",
    "    embedding_dims=100, \r\n",
    "    rate=0.5,  \r\n",
    "    embeddings = embeddings\r\n",
    ")\r\n",
    "model.compile(loss=MaskedLoss(), optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), metrics=[MaskedAccuracy()])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Embeddings hits: 8922, misses: 716 from the trained embeddings\n",
      "False\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "model.compile(loss=MaskedLoss(), optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), metrics=[MaskedAccuracy()])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "trigger_inputs = [[\"यूं\"]]\r\n",
    "trigger_inputs = preprocessor(trigger_inputs, training=False)\r\n",
    "generator_callback = SeqGenerateCallback(trigger_inputs)\r\n",
    "\r\n",
    "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"loss\", patience=3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "history = model.fit(x=x_train_seq, y=y_train_seq, batch_size=16, epochs=10, callbacks=[generator_callback, lr_scheduler])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "524/524 [==============================] - 55s 104ms/step - loss: 1.3065 - Masked-Accuracy: 0.8182\n",
      "current_seq:  [[  2 204   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
      "current_seq:  [[  2 204   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
      "current_seq:  [[   2  204 7340    0    0    0    0    0    0    0    0    0    0    0]]\n",
      "current_seq:  [[   2  204 7340 5878    0    0    0    0    0    0    0    0    0    0]]\n",
      "current_seq:  [[   2  204 7340 5878 5546    0    0    0    0    0    0    0    0    0]]\n",
      "current_seq:  [[   2  204 7340 5878 5546 2902    0    0    0    0    0    0    0    0]]\n",
      "current_seq:  [[   2  204 7340 5878 5546 2902 8757    0    0    0    0    0    0    0]]\n",
      "current_seq:  [[   2  204 7340 5878 5546 2902 8757 2333    0    0    0    0    0    0]]\n",
      "current_seq:  [[   2  204 7340 5878 5546 2902 8757 2333  129    0    0    0    0    0]]\n",
      "current_seq:  [[   2  204 7340 5878 5546 2902 8757 2333  129 8494    0    0    0    0]]\n",
      "current_seq:  [[   2  204 7340 5878 5546 2902 8757 2333  129 8494 1003    0    0    0]]\n",
      "current_seq:  [[   2  204 7340 5878 5546 2902 8757 2333  129 8494 1003 6919    0    0]]\n",
      "current_seq:  [[   2  204 7340 5878 5546 2902 8757 2333  129 8494 1003 6919 7806    0]]\n",
      "current_seq:  [[   2  204 7340 5878 5546 2902 8757 2333  129 8494 1003 6919 7806 2869]]\n",
      "after epoch 0 model generates: \n",
      "actual sequence:  [[   2  204 7340 5878 5546 2902 8757 2333  129 8494 1003 6919 7806 2869]]\n",
      "generated text sequence:  यूं तक़दीर माँझी लगन क़िताब अलोकिक लाली पहले उड़कर रोक नसीम चिंतित फ़रियाद\n",
      "Epoch 2/10\n",
      "524/524 [==============================] - 58s 111ms/step - loss: 1.2176 - Masked-Accuracy: 0.7879\n",
      "current_seq:  [[  2 204   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
      "current_seq:  [[  2 204   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
      "current_seq:  [[   2  204 7200    0    0    0    0    0    0    0    0    0    0    0]]\n",
      "current_seq:  [[   2  204 7200 7585    0    0    0    0    0    0    0    0    0    0]]\n",
      "current_seq:  [[   2  204 7200 7585 7294    0    0    0    0    0    0    0    0    0]]\n",
      "current_seq:  [[   2  204 7200 7585 7294 4673    0    0    0    0    0    0    0    0]]\n",
      "current_seq:  [[   2  204 7200 7585 7294 4673 4477    0    0    0    0    0    0    0]]\n",
      "current_seq:  [[   2  204 7200 7585 7294 4673 4477 3852    0    0    0    0    0    0]]\n",
      "current_seq:  [[   2  204 7200 7585 7294 4673 4477 3852 6466    0    0    0    0    0]]\n",
      "current_seq:  [[   2  204 7200 7585 7294 4673 4477 3852 6466 8666    0    0    0    0]]\n",
      "current_seq:  [[   2  204 7200 7585 7294 4673 4477 3852 6466 8666 1335    0    0    0]]\n",
      "current_seq:  [[   2  204 7200 7585 7294 4673 4477 3852 6466 8666 1335 5012    0    0]]\n",
      "current_seq:  [[   2  204 7200 7585 7294 4673 4477 3852 6466 8666 1335 5012  608    0]]\n",
      "current_seq:  [[   2  204 7200 7585 7294 4673 4477 3852 6466 8666 1335 5012  608 1135]]\n",
      "after epoch 1 model generates: \n",
      "actual sequence:  [[   2  204 7200 7585 7294 4673 4477 3852 6466 8666 1335 5012  608 1135]]\n",
      "generated text sequence:  यूं थमो जाऊँगा ताकता –सी ऊँघती धुले फट्टकार आलसी बढ़ने साहिर: बच्चे लहरों\n",
      "Epoch 3/10\n",
      "524/524 [==============================] - 61s 117ms/step - loss: 1.1625 - Masked-Accuracy: 0.7381\n",
      "current_seq:  [[  2 204   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
      "current_seq:  [[  2 204   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
      "current_seq:  [[   2  204 4548    0    0    0    0    0    0    0    0    0    0    0]]\n",
      "current_seq:  [[   2  204 4548 6407    0    0    0    0    0    0    0    0    0    0]]\n",
      "current_seq:  [[   2  204 4548 6407 8865    0    0    0    0    0    0    0    0    0]]\n",
      "current_seq:  [[   2  204 4548 6407 8865 4448    0    0    0    0    0    0    0    0]]\n",
      "current_seq:  [[   2  204 4548 6407 8865 4448 7231    0    0    0    0    0    0    0]]\n",
      "current_seq:  [[   2  204 4548 6407 8865 4448 7231 4487    0    0    0    0    0    0]]\n",
      "current_seq:  [[   2  204 4548 6407 8865 4448 7231 4487  484    0    0    0    0    0]]\n",
      "current_seq:  [[   2  204 4548 6407 8865 4448 7231 4487  484 7717    0    0    0    0]]\n",
      "current_seq:  [[   2  204 4548 6407 8865 4448 7231 4487  484 7717 5826    0    0    0]]\n",
      "current_seq:  [[   2  204 4548 6407 8865 4448 7231 4487  484 7717 5826 6949    0    0]]\n",
      "current_seq:  [[   2  204 4548 6407 8865 4448 7231 4487  484 7717 5826 6949 6507    0]]\n",
      "current_seq:  [[   2  204 4548 6407 8865 4448 7231 4487  484 7717 5826 6949 6507 8653]]\n",
      "after epoch 2 model generates: \n",
      "actual sequence:  [[   2  204 4548 6407 8865 4448 7231 4487  484 7717 5826 6949 6507 8653]]\n",
      "generated text sequence:  यूं आसानी बँटता अक्ल कमर तोहफ़े उमीदों बच्चों छलके मिलाप नन्हीं प्रयोजन आसनसोल\n",
      "Epoch 4/10\n",
      "524/524 [==============================] - 57s 108ms/step - loss: 1.1045 - Masked-Accuracy: 0.8148\n",
      "current_seq:  [[  2 204   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
      "current_seq:  [[  2 204   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
      "current_seq:  [[   2  204 8161    0    0    0    0    0    0    0    0    0    0    0]]\n",
      "current_seq:  [[   2  204 8161 7859    0    0    0    0    0    0    0    0    0    0]]\n",
      "current_seq:  [[   2  204 8161 7859  331    0    0    0    0    0    0    0    0    0]]\n",
      "current_seq:  [[   2  204 8161 7859  331 5604    0    0    0    0    0    0    0    0]]\n",
      "current_seq:  [[   2  204 8161 7859  331 5604 7013    0    0    0    0    0    0    0]]\n",
      "current_seq:  [[   2  204 8161 7859  331 5604 7013 1400    0    0    0    0    0    0]]\n",
      "current_seq:  [[   2  204 8161 7859  331 5604 7013 1400  661    0    0    0    0    0]]\n",
      "current_seq:  [[   2  204 8161 7859  331 5604 7013 1400  661 2823    0    0    0    0]]\n",
      "current_seq:  [[   2  204 8161 7859  331 5604 7013 1400  661 2823 1386    0    0    0]]\n",
      "current_seq:  [[   2  204 8161 7859  331 5604 7013 1400  661 2823 1386 6574    0    0]]\n",
      "current_seq:  [[   2  204 8161 7859  331 5604 7013 1400  661 2823 1386 6574 5392    0]]\n",
      "current_seq:  [[   2  204 8161 7859  331 5604 7013 1400  661 2823 1386 6574 5392 2360]]\n",
      "after epoch 3 model generates: \n",
      "actual sequence:  [[   2  204 8161 7859  331 5604 7013 1400  661 2823 1386 6574 5392 2360]]\n",
      "generated text sequence:  यूं ख़लिश चढ़ना धर्म रिसियाबहराइच द्वापरयुग गहराई चुप इनसे जनता पुलकित विकसित यूहीं\n",
      "Epoch 5/10\n",
      "524/524 [==============================] - 57s 108ms/step - loss: 1.0524 - Masked-Accuracy: 0.7949\n",
      "current_seq:  [[  2 204   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
      "current_seq:  [[  2 204   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
      "current_seq:  [[  2 204 800   0   0   0   0   0   0   0   0   0   0   0]]\n",
      "current_seq:  [[   2  204  800 5592    0    0    0    0    0    0    0    0    0    0]]\n",
      "current_seq:  [[   2  204  800 5592 1169    0    0    0    0    0    0    0    0    0]]\n",
      "current_seq:  [[   2  204  800 5592 1169 2038    0    0    0    0    0    0    0    0]]\n",
      "current_seq:  [[   2  204  800 5592 1169 2038 5569    0    0    0    0    0    0    0]]\n",
      "current_seq:  [[   2  204  800 5592 1169 2038 5569 5338    0    0    0    0    0    0]]\n",
      "current_seq:  [[   2  204  800 5592 1169 2038 5569 5338 2166    0    0    0    0    0]]\n",
      "current_seq:  [[   2  204  800 5592 1169 2038 5569 5338 2166 6996    0    0    0    0]]\n",
      "current_seq:  [[   2  204  800 5592 1169 2038 5569 5338 2166 6996 7358    0    0    0]]\n",
      "current_seq:  [[   2  204  800 5592 1169 2038 5569 5338 2166 6996 7358 6454    0    0]]\n",
      "current_seq:  [[   2  204  800 5592 1169 2038 5569 5338 2166 6996 7358 6454 1367    0]]\n",
      "current_seq:  [[   2  204  800 5592 1169 2038 5569 5338 2166 6996 7358 6454 1367  678]]\n",
      "after epoch 4 model generates: \n",
      "actual sequence:  [[   2  204  800 5592 1169 2038 5569 5338 2166 6996 7358 6454 1367  678]]\n",
      "generated text sequence:  यूं अधिकार रुलवाओगे पग जेहन रोकर वृक्षारोपण उजालों धरो ढूँढू फहराएं डुबो इंसानियत\n",
      "Epoch 6/10\n",
      "524/524 [==============================] - 56s 107ms/step - loss: 1.0049 - Masked-Accuracy: 0.8667\n",
      "current_seq:  [[  2 204   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
      "current_seq:  [[  2 204   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
      "current_seq:  [[   2  204 8085    0    0    0    0    0    0    0    0    0    0    0]]\n",
      "current_seq:  [[   2  204 8085 6620    0    0    0    0    0    0    0    0    0    0]]\n",
      "current_seq:  [[   2  204 8085 6620 4564    0    0    0    0    0    0    0    0    0]]\n",
      "current_seq:  [[   2  204 8085 6620 4564 4697    0    0    0    0    0    0    0    0]]\n",
      "current_seq:  [[   2  204 8085 6620 4564 4697 5333    0    0    0    0    0    0    0]]\n",
      "current_seq:  [[   2  204 8085 6620 4564 4697 5333 7475    0    0    0    0    0    0]]\n",
      "current_seq:  [[   2  204 8085 6620 4564 4697 5333 7475  279    0    0    0    0    0]]\n",
      "current_seq:  [[   2  204 8085 6620 4564 4697 5333 7475  279 5256    0    0    0    0]]\n",
      "current_seq:  [[   2  204 8085 6620 4564 4697 5333 7475  279 5256  960    0    0    0]]\n",
      "current_seq:  [[   2  204 8085 6620 4564 4697 5333 7475  279 5256  960 6454    0    0]]\n",
      "current_seq:  [[   2  204 8085 6620 4564 4697 5333 7475  279 5256  960 6454 6540    0]]\n",
      "current_seq:  [[   2  204 8085 6620 4564 4697 5333 7475  279 5256  960 6454 6540 1657]]\n",
      "after epoch 5 model generates: \n",
      "actual sequence:  [[   2  204 8085 6620 4564 4697 5333 7475  279 5256  960 6454 6540 1657]]\n",
      "generated text sequence:  यूं खेलते पालती आपने ढ़ोती वेदी झीलों सोच शीतलता कोना फहराएं पोशीदा खड़ा\n",
      "Epoch 7/10\n",
      "524/524 [==============================] - 62s 118ms/step - loss: 0.9552 - Masked-Accuracy: 0.8316\n",
      "current_seq:  [[  2 204   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
      "current_seq:  [[  2 204   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
      "current_seq:  [[  2 204 629   0   0   0   0   0   0   0   0   0   0   0]]\n",
      "current_seq:  [[   2  204  629 4809    0    0    0    0    0    0    0    0    0    0]]\n",
      "current_seq:  [[   2  204  629 4809 5549    0    0    0    0    0    0    0    0    0]]\n",
      "current_seq:  [[   2  204  629 4809 5549 8516    0    0    0    0    0    0    0    0]]\n",
      "current_seq:  [[   2  204  629 4809 5549 8516 3368    0    0    0    0    0    0    0]]\n",
      "current_seq:  [[   2  204  629 4809 5549 8516 3368   21    0    0    0    0    0    0]]\n",
      "current_seq:  [[   2  204  629 4809 5549 8516 3368   21 8425    0    0    0    0    0]]\n",
      "current_seq:  [[   2  204  629 4809 5549 8516 3368   21 8425 3930    0    0    0    0]]\n",
      "current_seq:  [[   2  204  629 4809 5549 8516 3368   21 8425 3930 7831    0    0    0]]\n",
      "current_seq:  [[   2  204  629 4809 5549 8516 3368   21 8425 3930 7831 4312    0    0]]\n",
      "current_seq:  [[   2  204  629 4809 5549 8516 3368   21 8425 3930 7831 4312  695    0]]\n",
      "current_seq:  [[   2  204  629 4809 5549 8516 3368   21 8425 3930 7831 4312  695 4858]]\n",
      "after epoch 6 model generates: \n",
      "actual sequence:  [[   2  204  629 4809 5549 8516 3368   21 8425 3930 7831 4312  695 4858]]\n",
      "generated text sequence:  यूं हवाएँ हरितिमा लखीमपुर उफ़ मुख्तसर ही कथाएं दलील चलेंगे खुश्क सको स्वीकारूँगी\n",
      "Epoch 8/10\n",
      "524/524 [==============================] - 57s 108ms/step - loss: 0.9131 - Masked-Accuracy: 0.8571\n",
      "current_seq:  [[  2 204   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
      "current_seq:  [[  2 204   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
      "current_seq:  [[  2 204 410   0   0   0   0   0   0   0   0   0   0   0]]\n",
      "current_seq:  [[   2  204  410 4891    0    0    0    0    0    0    0    0    0    0]]\n",
      "current_seq:  [[   2  204  410 4891 3136    0    0    0    0    0    0    0    0    0]]\n",
      "current_seq:  [[   2  204  410 4891 3136 1092    0    0    0    0    0    0    0    0]]\n",
      "current_seq:  [[   2  204  410 4891 3136 1092 6248    0    0    0    0    0    0    0]]\n",
      "current_seq:  [[   2  204  410 4891 3136 1092 6248 3932    0    0    0    0    0    0]]\n",
      "current_seq:  [[   2  204  410 4891 3136 1092 6248 3932 4719    0    0    0    0    0]]\n",
      "current_seq:  [[   2  204  410 4891 3136 1092 6248 3932 4719 8787    0    0    0    0]]\n",
      "current_seq:  [[   2  204  410 4891 3136 1092 6248 3932 4719 8787  703    0    0    0]]\n",
      "current_seq:  [[   2  204  410 4891 3136 1092 6248 3932 4719 8787  703 7511    0    0]]\n",
      "current_seq:  [[   2  204  410 4891 3136 1092 6248 3932 4719 8787  703 7511 6374    0]]\n",
      "current_seq:  [[   2  204  410 4891 3136 1092 6248 3932 4719 8787  703 7511 6374 6030]]\n",
      "after epoch 7 model generates: \n",
      "actual sequence:  [[   2  204  410 4891 3136 1092 6248 3932 4719 8787  703 7511 6374 6030]]\n",
      "generated text sequence:  यूं दुआ सोती शिकवों आईने बिंदिया दरिंदों ग़लत अभिमन्यु भले जौंक बटें भूरे\n",
      "Epoch 9/10\n",
      "524/524 [==============================] - 61s 117ms/step - loss: 0.8684 - Masked-Accuracy: 0.8384\n",
      "current_seq:  [[  2 204   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
      "current_seq:  [[  2 204   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
      "current_seq:  [[   2  204 3005    0    0    0    0    0    0    0    0    0    0    0]]\n",
      "current_seq:  [[   2  204 3005 5761    0    0    0    0    0    0    0    0    0    0]]\n",
      "current_seq:  [[   2  204 3005 5761 1817    0    0    0    0    0    0    0    0    0]]\n",
      "current_seq:  [[   2  204 3005 5761 1817 3903    0    0    0    0    0    0    0    0]]\n",
      "current_seq:  [[   2  204 3005 5761 1817 3903 1893    0    0    0    0    0    0    0]]\n",
      "current_seq:  [[   2  204 3005 5761 1817 3903 1893  784    0    0    0    0    0    0]]\n",
      "current_seq:  [[   2  204 3005 5761 1817 3903 1893  784 4651    0    0    0    0    0]]\n",
      "current_seq:  [[   2  204 3005 5761 1817 3903 1893  784 4651 6766    0    0    0    0]]\n",
      "current_seq:  [[   2  204 3005 5761 1817 3903 1893  784 4651 6766 8098    0    0    0]]\n",
      "current_seq:  [[   2  204 3005 5761 1817 3903 1893  784 4651 6766 8098 7864    0    0]]\n",
      "current_seq:  [[   2  204 3005 5761 1817 3903 1893  784 4651 6766 8098 7864 2147    0]]\n",
      "current_seq:  [[   2  204 3005 5761 1817 3903 1893  784 4651 6766 8098 7864 2147 8081]]\n",
      "after epoch 8 model generates: \n",
      "actual sequence:  [[   2  204 3005 5761 1817 3903 1893  784 4651 6766 8098 7864 2147 8081]]\n",
      "generated text sequence:  यूं सुनाना मुग़ल यारो दिवास्वप्नों बारहा चुकी अंगड़ाई पगलाई खुब चटखारे कल्याण खैरियत\n",
      "Epoch 10/10\n",
      "524/524 [==============================] - 57s 109ms/step - loss: 0.8269 - Masked-Accuracy: 0.8444\n",
      "current_seq:  [[  2 204   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
      "current_seq:  [[  2 204   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
      "current_seq:  [[   2  204 1280    0    0    0    0    0    0    0    0    0    0    0]]\n",
      "current_seq:  [[   2  204 1280 3653    0    0    0    0    0    0    0    0    0    0]]\n",
      "current_seq:  [[   2  204 1280 3653 7914    0    0    0    0    0    0    0    0    0]]\n",
      "current_seq:  [[   2  204 1280 3653 7914 1521    0    0    0    0    0    0    0    0]]\n",
      "current_seq:  [[   2  204 1280 3653 7914 1521 4925    0    0    0    0    0    0    0]]\n",
      "current_seq:  [[   2  204 1280 3653 7914 1521 4925 6273    0    0    0    0    0    0]]\n",
      "current_seq:  [[   2  204 1280 3653 7914 1521 4925 6273 6964    0    0    0    0    0]]\n",
      "current_seq:  [[   2  204 1280 3653 7914 1521 4925 6273 6964 1364    0    0    0    0]]\n",
      "current_seq:  [[   2  204 1280 3653 7914 1521 4925 6273 6964 1364 3478    0    0    0]]\n",
      "current_seq:  [[   2  204 1280 3653 7914 1521 4925 6273 6964 1364 3478 4634    0    0]]\n",
      "current_seq:  [[   2  204 1280 3653 7914 1521 4925 6273 6964 1364 3478 4634  980    0]]\n",
      "current_seq:  [[   2  204 1280 3653 7914 1521 4925 6273 6964 1364 3478 4634  980 5617]]\n",
      "after epoch 9 model generates: \n",
      "actual sequence:  [[   2  204 1280 3653 7914 1521 4925 6273 6964 1364 3478 4634  980 5617]]\n",
      "generated text sequence:  यूं विरह फुल घटाओं मरा सुहागीन बांसुरिया नखरों तकदीर भेजा अना हरी राधिका\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "model.save_weights(\"model_wieghts.h5\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "model.load_weights(\"model_wieghts.h5\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "inputs = [[\"मैं क्या \"]]\r\n",
    "# inputs = [[\"आशा\"]]\r\n",
    "inputs = preprocessor(inputs, training=False)\r\n",
    "model.generate(inputs, temperature=1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "current_seq:  [[ 2 20 32  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "current_seq:  [[ 2 20 32  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "current_seq:  [[ 2 20 32  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "current_seq:  [[   2   20   32 1207    0    0    0    0    0    0    0    0    0    0]]\n",
      "current_seq:  [[   2   20   32 1207 3686    0    0    0    0    0    0    0    0    0]]\n",
      "current_seq:  [[   2   20   32 1207 3686 4695    0    0    0    0    0    0    0    0]]\n",
      "current_seq:  [[   2   20   32 1207 3686 4695 1464    0    0    0    0    0    0    0]]\n",
      "current_seq:  [[   2   20   32 1207 3686 4695 1464 5607    0    0    0    0    0    0]]\n",
      "current_seq:  [[   2   20   32 1207 3686 4695 1464 5607 7069    0    0    0    0    0]]\n",
      "current_seq:  [[   2   20   32 1207 3686 4695 1464 5607 7069 1982    0    0    0    0]]\n",
      "current_seq:  [[   2   20   32 1207 3686 4695 1464 5607 7069 1982 4410    0    0    0]]\n",
      "current_seq:  [[   2   20   32 1207 3686 4695 1464 5607 7069 1982 4410 8506    0    0]]\n",
      "current_seq:  [[   2   20   32 1207 3686 4695 1464 5607 7069 1982 4410 8506 4251    0]]\n",
      "current_seq:  [[   2   20   32 1207 3686 4695 1464 5607 7069 1982 4410 8506 4251 6755]]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'मैं क्या गायब प्रांगण फ़नकार सहमी रिमझिम दुराचारी देवता क़िताबों उर्दू गुज़ारे पड़ोसी'"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "metadata": {}
  }
 ]
}