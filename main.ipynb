{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit (windows store)"
  },
  "interpreter": {
   "hash": "9b7910a43f22d8687f0de6ecfce0c1865e7017eb5d643397fde905e2a9a5ff87"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\r\n",
    "import tensorflow as tf\r\n",
    "import pandas as pd\r\n",
    "import tensorflow_text as tf_txt \r\n",
    "from typing import List, Dict"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "MAX_VOCAB_SIZE = 10000\r\n",
    "EMBEDDING_DIM = 200\r\n",
    "DFF = 512\r\n",
    "D_MODEL = 256\r\n",
    "MAX_SEQ_LEN = 10"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def get_angles(pos, i, dims):\r\n",
    "  angle_rates = 1 / (10000 ** ((2 * (i//2)) / dims))\r\n",
    "  return pos * angle_rates"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def positional_encoding(position, d_model):\r\n",
    "  angle_rads = get_angles(np.arange(position)[:, np.newaxis],\r\n",
    "                          np.arange(d_model)[np.newaxis, :],\r\n",
    "                          d_model)\r\n",
    "\r\n",
    "  # apply sin to even indices in the array; 2i\r\n",
    "  angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\r\n",
    "\r\n",
    "  # apply cos to odd indices in the array; 2i+1\r\n",
    "  angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\r\n",
    "\r\n",
    "  pos_encoding = angle_rads[np.newaxis, ...]\r\n",
    "\r\n",
    "  return tf.cast(pos_encoding, dtype=tf.float32)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "output = positional_encoding(10, 200)\r\n",
    "output.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TensorShape([1, 10, 200])"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def lookahead_mask(seq):\r\n",
    "    return 1 - tf.linalg.band_part(tf.ones((seq, seq)), -1, 0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "output = lookahead_mask(4)\r\n",
    "output.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TensorShape([4, 4])"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "source": [
    "class Preprocessor:\r\n",
    "    def __init__(self, vocab_size, seq_len=10):\r\n",
    "        self.seq_len = seq_len\r\n",
    "        self.vocab: List[str] = None\r\n",
    "        self.word_ids: Dict[str, int] = None\r\n",
    "        self.rev_word_ids:  Dict[int, str] = None\r\n",
    "        self.vocab_size = None\r\n",
    "        self.tokenizer = tf.keras.layers.experimental.preprocessing.TextVectorization(max_tokens=vocab_size,\r\n",
    "                                        output_sequence_length=self.seq_len, standardize=self.custom_standardize\r\n",
    "                                        )\r\n",
    "\r\n",
    "    def __call__(self, inputs):\r\n",
    "\r\n",
    "        # encoding into utf8\r\n",
    "        encoded_seq = tf_txt.normalize_utf8(inputs, \"NFKD\")\r\n",
    "\r\n",
    "        # tokenizing into 'seq_len' num of tokens\r\n",
    "        tokenized_seq = self.tokenizer(self.add_extra(encoded_seq))\r\n",
    "\r\n",
    "        # adding end token back if gets cliped\r\n",
    "        end_token = np.array([self.word_ids[\"[KHATAM]\"]])[:, np.newaxis]\r\n",
    "        tokenized_seq = tokenized_seq.numpy()\r\n",
    "        tokenized_seq[(tokenized_seq[:, -1]==0)==0, -1] = end_token\r\n",
    "\r\n",
    "        # returning as tensor\r\n",
    "        return tf.constant(tokenized_seq)\r\n",
    "\r\n",
    "    @staticmethod\r\n",
    "    def add_extra(inputs):\r\n",
    "        inputs = tf.constant(inputs)\r\n",
    "        return [[\"[SURU] \"]]+inputs+[[\" [KHATAM]\"]]\r\n",
    "    \r\n",
    "    def custom_standardize(self, text):\r\n",
    "        return text\r\n",
    "\r\n",
    "    \r\n",
    "    def build_vocab(self, inputs):\r\n",
    "        self.tokenizer.adapt(self.add_extra(inputs))\r\n",
    "        self.vocab = self.tokenizer.get_vocabulary()\r\n",
    "        self.vocab_size = len(self.vocab)\r\n",
    "        self.build_dictionary(self.vocab)\r\n",
    "        return self.vocab\r\n",
    "\r\n",
    "    def build_dictionary(self, vocab_list: List[str]):\r\n",
    "        word_ids = dict()\r\n",
    "        rev_word_ids = dict()\r\n",
    "        for i, item in enumerate(vocab_list):\r\n",
    "            word_ids[item] = i\r\n",
    "            rev_word_ids[i] = item\r\n",
    "        self.word_ids = word_ids\r\n",
    "        self.rev_word_ids = rev_word_ids\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "source": [
    "preprocessor = Preprocessor(vocab_size=100, seq_len=10)\r\n",
    "inputs = [[\"जैसा \"], [\"i am fine, what about you. i mean ? \"]]\r\n",
    "vocab = preprocessor.build_vocab(inputs)\r\n",
    "print(vocab)\r\n",
    "print(preprocessor(inputs))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['', '[UNK]', 'i', '[SURU]', '[KHATAM]', 'जैसा', 'you.', 'what', 'mean', 'fine,', 'am', 'about', '?']\n",
      "tf.Tensor(\n",
      "[[ 3  5  4  0  0  0  0  0  0  0]\n",
      " [ 3  2 10  9  7 11  6  2  8  4]], shape=(2, 10), dtype=int64)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "class FFN(tf.keras.layers.Layer):\r\n",
    "  def  __init__(self, d_model, dff):\r\n",
    "        super().__init__()\r\n",
    "        self.dff = dff\r\n",
    "        self.dense1 = tf.keras.layers.Dense(dff, activation=\"relu\")\r\n",
    "        self.dense2 = tf.keras.layers.Dense(d_model)\r\n",
    "\r\n",
    "  def call(self, inputs):\r\n",
    "        outputs = self.dense1(inputs)\r\n",
    "        outputs = self.dense2(outputs)\r\n",
    "        return outputs\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "class Block(tf.keras.layers.Layer):\r\n",
    "    def __init__(self, d_model: int, dff: int = 2048, heads: int = 8, rate: int = 0.1):\r\n",
    "        super().__init__()\r\n",
    "\r\n",
    "        assert d_model%heads==0\r\n",
    "        #parameters\r\n",
    "        self.d_model = d_model      # model dims \r\n",
    "        self.dff = dff                           # ffn dense layer units\r\n",
    "        self.heads = heads               # number of heads\r\n",
    "\r\n",
    "        #layers\r\n",
    "        self.ffn = FFN(d_model, dff)\r\n",
    "        self.ln1 = tf.keras.layers.LayerNormalization()\r\n",
    "        self.ln2 = tf.keras.layers.LayerNormalization()\r\n",
    "        self.wq = tf.keras.layers.Dense(self.d_model)\r\n",
    "        self.wv = tf.keras.layers.Dense(self.d_model)\r\n",
    "        self.wi = tf.keras.layers.Dense(self.d_model)\r\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\r\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\r\n",
    "        self.mha = tf.keras.layers.MultiHeadAttention(num_heads=self.heads, key_dim=self.d_model)\r\n",
    "\r\n",
    "    # def build(self, input_shape):\r\n",
    "    #     self.mha = tf.keras.layers.MultiHeadAttention(num_heads=self.heads, key_dim=d_model)\r\n",
    "\r\n",
    "    def call(self, inputs, training=False, mask=None):\r\n",
    "        q = self.wq(inputs)     #(None, seq_len, d_model)\r\n",
    "        v = self.wv(inputs)      #(None, seq_len, d_model)\r\n",
    "\r\n",
    "        # projecting on higher dimension to add with attention_outputs in  ln\r\n",
    "        inputs = self.wi(inputs)  #(None, seq_len, d_model)\r\n",
    "        attention_outputs = self.mha(query=q, value=v, attention_mask=mask)      # output shape (None, query_len, d_model)\r\n",
    "        dropped_attention_outputs = self.dropout1(attention_outputs, training=training)\r\n",
    "        outputs = self.ln1(inputs+dropped_attention_outputs)\r\n",
    "\r\n",
    "        ffn_outputs = self.ffn(outputs)     # output shape (None, query_len, d_model)\r\n",
    "        dropped_ffn_outputs = self.dropout1(ffn_outputs, training=training)\r\n",
    "        outputs = self.ln2(inputs+dropped_ffn_outputs)        # output shape (None, query_len, d_model)\r\n",
    "        \r\n",
    "        return outputs"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "layer = Block(d_model=8, dff=256, heads=4)\r\n",
    "mask = tf.keras.Input(shape=[4, 4])\r\n",
    "source = tf.keras.Input(shape=[4, 100])\r\n",
    "outputs = layer(inputs=source, mask=mask)\r\n",
    "print(outputs.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(None, 4, 8)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "class Poet(tf.keras.models.Model):\r\n",
    "    def __init__(self, preprocessor, num_blocks=1, d_model=256, dff=512, heads=8, embedding_dims=100):\r\n",
    "        super().__init__()\r\n",
    "        self.d_model = d_model\r\n",
    "        self.preprocessor = preprocessor\r\n",
    "        self.num_blocks = num_blocks\r\n",
    "        self.embedding_dims = embedding_dims\r\n",
    "        # generating pos encoding now to save time while calling call()(as it is constant for all examples)\r\n",
    "        self.pos_encoding = positional_encoding(self.preprocessor.seq_len, self.embedding_dims)\r\n",
    "        self.embedding_layer = tf.keras.layers.Embedding(input_dim=self.preprocessor.vocab_size, \r\n",
    "                                            output_dim=self.embedding_dims, mask_zero=True, input_length=self.preprocessor.seq_len\r\n",
    "                                            )\r\n",
    "        self.blocks = [Block(d_model=self.d_model, dff=dff, heads=heads) for i in range(self.num_blocks)]\r\n",
    "\r\n",
    "        self.final_layer = tf.keras.layers.Dense(self.preprocessor.vocab_size, activation=\"softmax\")\r\n",
    "\r\n",
    "\r\n",
    "    def call(self, inputs):\r\n",
    "        embeddings = self.embedding_layer(inputs)\r\n",
    "\r\n",
    "        # adding positional encoding\r\n",
    "        x = embeddings + self.pos_encoding\r\n",
    "        \r\n",
    "        # generate lookahead mask\r\n",
    "        mask = lookahead_mask(self.preprocessor.seq_len)\r\n",
    "\r\n",
    "        # passing rich attention embedding through each block\r\n",
    "        for block in self.blocks:\r\n",
    "            x = block(x, mask=mask)\r\n",
    "        \r\n",
    "        outputs = self.final_layer(x)\r\n",
    "        \r\n",
    "        return outputs"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "source": [
    "string_inputs = [[\"जैसा\"], [\"i am fine, what about you. ? i mean\"]]\r\n",
    "preprocess_inputs = preprocessor(string_inputs)\r\n",
    "print(preprocess_inputs.shape)\r\n",
    "poet = Poet(preprocessor=preprocessor)\r\n",
    "outputs = poet.call(preprocess_inputs)\r\n",
    "print(outputs.shape)        # shape (None, seq_len, vocab_size)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(2, 10)\n",
      "(2, 10, 13)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "source": [
    "class ModelLoss(tf.keras.losses.Loss):\r\n",
    "    def __init__(self):\r\n",
    "        super().__init__()\r\n",
    "        self.name=\"masked-loss\"\r\n",
    "        self.loss_function = tf.keras.losses.SparseCategoricalCrossentropy()\r\n",
    "\r\n",
    "    def call(self, y_true, y_pred):\r\n",
    "        mask = tf.cast(tf.math.logical_not(tf.math.equal(y_true, 0)), dtype=tf.float32)\r\n",
    "        print(mask)\r\n",
    "        loss = self.loss_function(y_true, y_pred)\r\n",
    "        print(loss)\r\n",
    "        loss *= mask\r\n",
    "        return loss\r\n",
    "\r\n",
    "class ModelAccuracy(tf.keras.metrics.Metric):\r\n",
    "    def __init__(self):\r\n",
    "        super().__init__(name=\"Masked-Accuracy\")\r\n",
    "        self.true_positives = self.add_weight(name='tp', initializer='zeros')\r\n",
    "\r\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\r\n",
    "        mask = tf.cast(tf.math.logical_not(tf.math.equal(y_true, 0)), dtype=tf.float32)\r\n",
    "        accuracies = tf.math.equal(y_true, tf.argmax(y_pred, axis=-1))\r\n",
    "        accuracies *= mask\r\n",
    "        \r\n",
    "        if sample_weight is not None:\r\n",
    "            sample_weight = tf.cast(sample_weight, self.dtype)\r\n",
    "            sample_weight = tf.broadcast_to(sample_weight, accuracies.shape)\r\n",
    "            values = tf.multiply(accuracies, sample_weight)\r\n",
    "\r\n",
    "        return tf.reduce_sum(values)/tf.constant(y_true.shape[-1])\r\n",
    "    \r\n",
    "    def result(self):\r\n",
    "        return self.true_positives"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "source": [
    "loss = ModelLoss().call(preprocess_inputs, outputs)\r\n",
    "print(loss.shape)\r\n",
    "\r\n",
    "accuracy = ModelAccuracy().update_state(preprocess_inputs, outputs)\r\n",
    "print(accuracy.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tf.Tensor(\n",
      "[[1. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]], shape=(2, 10), dtype=float32)\n",
      "tf.Tensor(4.679945, shape=(), dtype=float32)\n",
      "(2, 10)\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "InvalidArgumentError",
     "evalue": "in user code:\n\n    C:\\Users\\tusha\\AppData\\Local\\Temp/ipykernel_8236/609337132.py:23 update_state  *\n        accuracies *= mask\n    C:\\Users\\tusha\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\tensorflow\\python\\ops\\math_ops.py:1234 binary_op_wrapper\n        return func(x, y, name=name)\n    C:\\Users\\tusha\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\tensorflow\\python\\ops\\math_ops.py:1575 _mul_dispatch\n        return multiply(x, y, name=name)\n    C:\\Users\\tusha\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\tusha\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\tensorflow\\python\\ops\\math_ops.py:530 multiply\n        return gen_math_ops.mul(x, y, name)\n    C:\\Users\\tusha\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py:6239 mul\n        _ops.raise_from_not_ok_status(e, name)\n    C:\\Users\\tusha\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\tensorflow\\python\\framework\\ops.py:6897 raise_from_not_ok_status\n        six.raise_from(core._status_to_exception(e.code, message), None)\n    <string>:3 raise_from\n        \n\n    InvalidArgumentError: Value for attr 'T' of bool is not in the list of allowed values: bfloat16, half, float, double, uint8, int8, uint16, int16, int32, uint32, uint64, int64, complex64, complex128\n    \t; NodeDef: {{node Mul}}; Op<name=Mul; signature=x:T, y:T -> z:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_UINT8, DT_INT8, DT_UINT16, DT_INT16, DT_INT32, DT_UINT32, DT_UINT64, DT_INT64, DT_COMPLEX64, DT_COMPLEX128]; is_commutative=true> [Op:Mul]\n",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8236/1170110199.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModelAccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreprocess_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\tensorflow\\python\\keras\\utils\\metrics_utils.py\u001b[0m in \u001b[0;36mdecorated\u001b[1;34m(metric_obj, *args, **kwargs)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_context_for_symbolic_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m       \u001b[0mupdate_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdate_state_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mupdate_op\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# update_op will be None in eager execution.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m       \u001b[0mmetric_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mupdate_op\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\tensorflow\\python\\keras\\metrics.py\u001b[0m in \u001b[0;36mupdate_state_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    175\u001b[0m         \u001b[0mcontrol_status\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m         \u001b[0mag_update_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj_update_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontrol_status\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 177\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mag_update_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    178\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdef_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFunction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    693\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    694\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ag_error_metadata'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 695\u001b[1;33m           \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    696\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    697\u001b[0m           \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: in user code:\n\n    C:\\Users\\tusha\\AppData\\Local\\Temp/ipykernel_8236/609337132.py:23 update_state  *\n        accuracies *= mask\n    C:\\Users\\tusha\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\tensorflow\\python\\ops\\math_ops.py:1234 binary_op_wrapper\n        return func(x, y, name=name)\n    C:\\Users\\tusha\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\tensorflow\\python\\ops\\math_ops.py:1575 _mul_dispatch\n        return multiply(x, y, name=name)\n    C:\\Users\\tusha\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\tusha\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\tensorflow\\python\\ops\\math_ops.py:530 multiply\n        return gen_math_ops.mul(x, y, name)\n    C:\\Users\\tusha\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py:6239 mul\n        _ops.raise_from_not_ok_status(e, name)\n    C:\\Users\\tusha\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\tensorflow\\python\\framework\\ops.py:6897 raise_from_not_ok_status\n        six.raise_from(core._status_to_exception(e.code, message), None)\n    <string>:3 raise_from\n        \n\n    InvalidArgumentError: Value for attr 'T' of bool is not in the list of allowed values: bfloat16, half, float, double, uint8, int8, uint16, int16, int32, uint32, uint64, int64, complex64, complex128\n    \t; NodeDef: {{node Mul}}; Op<name=Mul; signature=x:T, y:T -> z:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_UINT8, DT_INT8, DT_UINT16, DT_INT16, DT_INT32, DT_UINT32, DT_UINT64, DT_INT64, DT_COMPLEX64, DT_COMPLEX128]; is_commutative=true> [Op:Mul]\n"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}